{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regras de Associação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c81b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9071944",
   "metadata": {},
   "source": [
    "## Análise do conjunto de dados\n",
    "\n",
    "Regras de associação são algoritmos que extraem conjuntos de itens frequentes em datasets que cada instância é um conjunto de itens. Vamos visualizar o que isso significa.\n",
    "\n",
    "Vamos observar o dataset de compras de um supermercado. Segue o link para mais informações [dataset](https://archive.ics.uci.edu/dataset/352/online+retail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c1794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv(\"https://raw.githubusercontent.com/cynthiamaia/Monitoria-DeepLearning-CIN-AI/main/Datasets/Ironline_retail.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987da23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff64dc6",
   "metadata": {},
   "source": [
    "Aqui temos diversas informações sobre compras em um supermercado:\n",
    "\n",
    "- (_InvoiceNo_) o número da fatura, identificador de uma compra\n",
    "- (_StockCode_) o código de certo produto no estoque\n",
    "- (_Description_) a descrição do produto\n",
    "- (_Quantity_) a quantidade de produtos que foi comprada\n",
    "- (_InvoiceDate_) o dia da compra\n",
    "- (_UnitPrice_) o preço por unidade\n",
    "- (_CustomerID_) o id do consumidor\n",
    "- (_Country_) o país de venda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5313a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos olhar todos os países existentes\n",
    "print(df[\"Country\"].unique())\n",
    "# print(df[\"Country\"].value_counts())\n",
    "\n",
    "# dos países, vamos escolher apenas as vendas feitas no Reino Unido, apenas pelo fato de existirem mais vendas no dataset\n",
    "country = \"United Kingdom\"\n",
    "sales = df[df[\"Country\"] == country]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826cd803",
   "metadata": {},
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc835a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C - indica cancelamento\"\n",
    "sales[sales[\"InvoiceNo\"].str.contains(\"C\")].head(10)\n",
    "\n",
    "# sales[sales[\"Description\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78724194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# antes de utilizar nosso dataset, precisamos fazer alguns pre-processamentos:\n",
    "# remover todas as instâncias que não possuem description\n",
    "filtered_sales = sales.dropna(axis=0, subset=[\"Description\"]) \n",
    "print(filtered_sales.shape)\n",
    "# transformar em strings\n",
    "filtered_sales[\"InvoiceNo\"] = filtered_sales[\"InvoiceNo\"].astype(\"str\")\n",
    "# remover instancias que contenham \"C\" no _InvoiceNo_, representando instancias que não possuem essa feature\n",
    "filtered_sales = filtered_sales[~filtered_sales[\"InvoiceNo\"].str.contains(\"C\")]\n",
    "\n",
    "# remover espaços desnecessários no começo e fim de cada _Description_\n",
    "filtered_sales[\"Description\"] = filtered_sales[\"Description\"].str.strip()\n",
    "filtered_sales[\"Description\"] = filtered_sales[\"Description\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e3174f",
   "metadata": {},
   "source": [
    "Como o dataset a ser avaliado deverá consistir em conjuntos de itens, vamos transformar cada compra em um conjunto de itens. Note que um conjunto não possui informação sobre quantidade de elementos repetidos. Portanto, a coluna com a contagem de cada item deve ser removida, indicando apenas a presença daquele item em uma compra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc393463",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_set = filtered_sales.groupby(['InvoiceNo', 'Description'])[\"Quantity\"].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\n",
    "sales_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b8174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_set[[\"POSTAGE\", \"DOTCOM POSTAGE\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8beb7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# existem algumas vendas que tiveram algum tipo de problema, vamos remove-las a partir no index 4057\n",
    "\n",
    "#vamos reduzir o número de colunas para 1500\n",
    "sales_set = sales_set.iloc[:, :1500]\n",
    "print(sales_set.shape)\n",
    "\n",
    "# também estão descritos o tipo de postagem, se pela internet ou não, vamos remove-los\n",
    "sales_set = sales_set.drop(\"POSTAGE\", axis=1, errors=\"ignore\")\n",
    "sales_set = sales_set.drop(\"DOTCOM POSTAGE\", axis=1, errors=\"ignore\")\n",
    "\n",
    "# nosso dataset final\n",
    "sales_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90da037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora, vamos transformar o dataset de uma contagem de itens, para apenas conjuntos\n",
    "# faremos isso transformando toda contagem para uma presença ou não do item\n",
    "\n",
    "count_to_set = lambda x: x > 0 # aqui se uma venda possui pelo menos 1 item, afime True, caso contrário, False\n",
    "sales_set = sales_set.applymap(count_to_set)\n",
    "\n",
    "print(sales_set.shape)\n",
    "sales_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a27c56",
   "metadata": {},
   "source": [
    "Após esse paço de pre-processamento, conseguimos extrair quais itens são comprados em conjunto com maior frequência para todas as vendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### APRIORI\n",
    "Inicialmente, vamos utilizar o algoritmo a priori. Nele precisamos indicar qual a repetição mínima necessária de repetição que buscamos. Por exemplo, se quisermos apenas as repetições que aconteçam pelo menos $n\\%$ das vezes.\n",
    "\n",
    "O algoritmo funciona por criar todas as combinações possíveis de conjuntos e então checar suas frequências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# use_colnames retorna o itemset como nomes ao invés de indices das colunas\n",
    "frequency_set = apriori(sales_set, min_support=0.01, use_colnames=True)\n",
    "print(frequency_set)\n",
    "\n",
    "#Unable to allocate 9.89 GiB for an array with shape (263901, 2, 20122) and data type bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63601c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perceba que temos muitas conjuntos com apenas um elemento\n",
    "# vamos filtrar esses conjuntos que tem apenas um elemento\n",
    "\n",
    "def filter_set_lenght(input_set, lenght=2):\n",
    "    input_set['set_lenght'] = input_set['itemsets'].apply(lambda x: len(x))\n",
    "    new_set = input_set[input_set['set_lenght'] >= lenght]\n",
    "    new_set.reset_index(inplace=True, drop=True)\n",
    "    return new_set\n",
    "    \n",
    "combo_set = filter_set_lenght(frequency_set)\n",
    "print(combo_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32123d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolhendo a combinação de itens com maior repetição\n",
    "def get_highest_support(input_set):\n",
    "    instance = input_set.iloc[input_set[\"support\"].idxmax()]\n",
    "    return instance\n",
    "\n",
    "# e criando uma função auxiliar para mostrar as estatísticas do nosso combo a partir do nosso conjunto de vendas\n",
    "def print_combo_stats(combo, sales):\n",
    "    print(\"itens: %s\"%(str(tuple(combo[\"itemsets\"]))))\n",
    "    print(\"frequencia %.2f%%\" %(float(combo[\"support\"])*100))\n",
    "    print(\"vendas totais do combo: %d\"%(float(combo[\"support\"]) * sales.shape[0]))\n",
    "\n",
    "combo = get_highest_support(combo_set)\n",
    "print_combo_stats(combo, sales_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df31b7f",
   "metadata": {},
   "source": [
    "### FP-Growth\n",
    "Ao contrário do algoritmo a priori, FP-Growth não precisa criar todas os conjuntos de combinações. Para datasets em que a quantidade de combinações é muito grande, ele possui uma vantagem sobre seu tempo de execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f84195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caso o import fpgrowth falhe, descomente a linha abaixo\n",
    "# !pip install mlxtend -U\n",
    "\n",
    "from mlxtend.frequent_patterns.fpgrowth import fpgrowth\n",
    "\n",
    "# use_colnames retorna o itemset como nomes ao invés de indices das colunas\n",
    "frequency_set = fpgrowth(sales_set, min_support=0.01, use_colnames=True)\n",
    "print(frequency_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_set = filter_set_lenght(frequency_set)\n",
    "combo = get_highest_support(combo_set)\n",
    "print_combo_stats(combo, sales_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e21fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temos o mesmo resultado, mas vamos avaliar o tempo de execução entre cada algoritmo...\n",
    "\n",
    "from time import time\n",
    "t0 = time()\n",
    "frequency_set = apriori(sales_set, min_support=0.01, use_colnames=True)\n",
    "t1 = time()\n",
    "frequency_set = fpgrowth(sales_set, min_support=0.01, use_colnames=True)\n",
    "t2 = time()\n",
    "\n",
    "print(\"APriori(t_delta): %f\" %(t1-t0))\n",
    "print(\"FP-Growth(t_delta): %f\" %(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf954b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84494beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
